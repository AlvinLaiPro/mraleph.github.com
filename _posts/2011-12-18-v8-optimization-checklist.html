---
layout: blogpost
title: I-want-to-optimize-my-JS-application-on-V8 checklist
date: 2011-12-18
---

<p>Samurais had something called <em>bushido</em>, way of the warrior, code of conduct they had to follow. In similar manner you have to follow certain <em>opt-d≈ç</em> if you want to optimize your application. I have tried to sketch such a path in my nodecamp.eu talk "<a href="http://s3.mrale.ph/nodecamp.eu/#1">Understanding V8</a>" and <a href="https://plus.google.com/111909581069462963574">+Daniel Clifford</a> tried to do the same in "<a href="https://mkw.st/p/gdd11-berlin-v8-performance-tuning-tricks/#1">V8 Performance Tuning Tricks</a>" talk on GDD11 in Berlin. But not everybody has seen those talks and the question keeps coming back again. So I decided to write down a quick check list for developers who want to optimize their apps. tl;dr version of my checklist is: "<em>Understand before you act</em>".&nbsp;</p>
<p><a id="talks-and-posts" name="talks-and-posts"></a></p>
<h2>Understanding V8 and&nbsp;beyond&nbsp;[talks and posts]</h2>
<p><strong>UPDATE Nov 6 2012</strong> More and more talks are being given about optimizing for V8 and understanding it's internals so I decided to maintain a list of them here. If I missed some interesting/useful blog post or talk about <em>any</em> JavaScript VM please <a href="mailto:me@mrale.ph">send me a link</a> and I will add it.</p>
<ul>
<li>Practical recommendations and optimization walk-throughs for V8
<ul>
<li>Understanding V8 (me, nodecamp.eu 2011) <a href="http://s3.mrale.ph/nodecamp.eu/#1">[slides]</a></li>
<li>V8 Performance Tuning Tricks (<a href="https://plus.google.com/111909581069462963574">+Daniel Clifford</a>, GDD2011 Berlin) <a href="https://mkw.st/p/gdd11-berlin-v8-performance-tuning-tricks/#1">[slides]</a></li>
<li>Console to Chrome (<a href="https://plus.google.com/111647958621817995641">+Lilli Thompson</a>, GDC 2012) <a href="http://console-to-chrome.appspot.com/#8">[slides]</a> <a href="http://www.youtube.com/watch?v=XAqIpGU8ZZk#t=9m0s">[video]</a></li>
<li>Breaking the JavaScript Speed Barrier with V8 (<a href="https://plus.google.com/111909581069462963574">+Daniel Clifford</a>, Google I/O 2012) <a href="http://v8-io12.appspot.com/index.html">[slides]</a> <a href="http://www.youtube.com/watch?v=UJPdhx5zTaw">[video]</a></li>
<li><a href="http://floitsch.blogspot.dk/2012/03/optimizing-for-v8-introduction.html">Optimizing for V8</a> (series of blog posts from <a href="https://plus.google.com/103716596068416580695">+Florian Loitsch</a>, based on his experience writing dart2js compiler)</li>
<li><a href="http://www.html5rocks.com/en/tutorials/speed/v8/">Performance tips for JavaScript in V8</a> by <a href="https://plus.sandbox.google.com/106422711035746240826/posts">+Chris Wilson</a></li>
<li><a href="http://coding.smashingmagazine.com/2012/11/05/writing-fast-memory-efficient-javascript/">Writing Fast, Memory-Efficient JavaScript</a> by <a href="https://twitter.com/addyosmani">Addy Osmani</a></li>
</ul>
</li>
<li>V8 talks (old ones might contain outdated information)
<ul>
<li>V8: High Performance JavaScript Engine in Google Chrome (<a href="https://plus.google.com/118332431854651588625">+Kevin Millikin</a>, GDD 2008 London) <a href="http://www.youtube.com/watch?v=lZnaaUoHPhs">[video]</a> &nbsp;</li>
<li>V8 Internals (<a href="https://plus.google.com/105218366515825183046">+Mads Ager</a>, Google I/O 2009)&nbsp;<a href="http://www.youtube.com/watch?v=FrufJFBSoQY">[video]</a></li>
<li>Erik Meijer and <a href="https://plus.google.com/117369940038227331789">+Lars Bak</a> on&nbsp;Channel 9: <a href="http://channel9.msdn.com/Shows/Going+Deep/Expert-to-Expert-Erik-Meijer-and-Lars-Bak-Inside-V8-A-Javascript-Virtual-Machine">Inside V8 - A Javascript Virtual Machine</a>&nbsp;(2009)</li>
<li>Crankshaft: Turbocharging the Next Generation of Web (<a href="https://plus.google.com/100258330325630692559">+Kasper Lund</a>, YOW 2011) <a href="http://yow.eventer.com/events/1004/talks/1017">[video]</a> <a href="http://gotocon.com/dl/goto-aarhus-2011/slides/KasperLund_CrankshaftTurbochargingTheNextGenerationOfWebApplications.pdf">[slides]</a></li>
</ul>
</li>
<li>Fundamentals of V8 and other JS VMs
<ul>
<li><a href="http://twitter.com/andywingo">Andy Wingo</a> <a href="http://wingolog.org/tags/v8">blogs about his adventures in V8's</a> and JavaScriptCore's compilation pipelines</li>
<li><a href="http://twitter.com/dmandelin">David Mandelin</a>'s (SpiderMonkey TL) talk&nbsp;Know Your Engines (Velocity Conf 2011) <a href="http://people.mozilla.com/~dmandelin/KnowYourEngines_Velocity2011.pdf">[slides]</a> <a href="http://www.youtube.com/watch?v=dtSOKLvdAto">[video]</a>.</li>
<li>I am trying to <a href="http://blog.mrale.ph/post/24351748336/explaining-js-vm-in-js">explain <em>inline-caching</em> used by JavaScript VMs by writing IC <em>in</em> JavaScript</a>, also see my talk "V8 Inside Out" from WebRebels 2012 <a href="http://s3.mrale.ph/webrebels2012.pdf">[slides]</a> <a href="http://vimeo.com/43334972">[video]</a></li>
<li><a href="http://channel9.msdn.com/Events/Build/2012/4-000">Building High-Performing JavaScript for Modern Engines</a>: performance recommendations from Microsoft's JavaScript team (tailored to Chakra).</li>
</ul>
</li>
<li>Miscellaneous
<ul>
<li>Can V8 do that?! (me, JSConf 2012) <a href="http://s3.mrale.ph/jsconf2012.pdf">[slides]</a> <a href="http://blip.tv/jsconf/jsconf2012-vyacheslav-egorov-6141593">[vides]</a></li>
<li><a href="http://channel9.msdn.com/Shows/Going+Deep/Lars-Bak-and-Steve-Lucco-Chakra-V8-JavaScript-Open-Source">Channel 9: Lars Bak and Steve Lucco: Chakra, V8, JavaScript, Open Source</a></li>
<li><a href="http://www.youtube.com/watch?v=ZhshEZIV2F4">The Footprint of Performance (video)</a>: <a href="https://twitter.com/starzi">Michael Starzinger</a> describes memory implications of various programming patterns at JSConf EU 2012</li>
</ul>
</li>
</ul>
<h2>Do you understand what the application is trying to do and how?</h2>
<p>The more you understand about your app the better you can optimize it. Sometimes a tricky algorithm or a cache placed in right place will yield more improvements than any local tweaking. Understanding your application in large is a very difficult problem which requires special tooling and discipline. I highly recommend to read <a href="https://twitter.com/#!/coda">@coda</a>'s <a href="http://codahale.com/codeconf-2011-04-09-metrics-metrics-everywhere.pdf">Metrics Metrics Everywhere</a> talk if you want to get a glimpse of that world. Sometimes it is possible to split big application into pieces and optimize them separately but there is no guarantee that overall gain will not be lost when those pieces are connected back together.</p>
<h2>Did you profile your application with built in statistical profiler?</h2>
<p>Profiling helps to discover obvious hot spots. Don't waste time rewriting places that occupy 0.0001% of running time. Concentrate your efforts on those that are high on the profile. If you are using V8's tick processors keep in mind that <code>LazyCompile: </code> prefix does <strong>not</strong> mean that this time was spent in compiler, it just means that the function itself was compiled lazily. Statistical profiler is not the most accurate tool in the world and might miss overheads that are finely spread across execution (as sampling interval is 2ms). Tools like dtrace, perf, Instruments, VTune might provide a more fine grained picture but they do not necessarily have support for JITed code (see below).</p>
<h3>JavaScript function is high on the profile</h3>
<p>Ensure that this function is optimized and Crankshaft friendly. V8's tick processing scripts mark optimized functions with <code>*</code> (asterisk) and non-optimized with <code>~</code> (tilda). You can also use <code>--trace-opt --trace-deopt</code> flags to see what Crankshaft does with your program. Deoptimizations happen when assumptions made by the compiler does not match program's runtime behavior, bailouts happens when compiler can't compile the function with optimizations for some reason. [note that in V8 prior to version 3.13.4 you'll need to supply <code>--trace-bailout</code> to see optimizing compiler bailouts] If you want to understand ideas behind V8 optimization pipeline I recommend to start by reading Andy Wingo's <a href="http://wingolog.org/archives/2011/07/05/v8-a-tale-of-two-compilers">A Tale of Two Compilers</a> post.</p>
<p>In general it's a good idea to know more about modern JavaScript VMs, especially their strengths and weaknesses. I recommend going through&nbsp;<a href="http://twitter.com/dmandelin">David Mandelin</a>'s talk&nbsp;<a href="http://people.mozilla.com/~dmandelin/KnowYourEngines_Velocity2011.pdf">Know Your Engines</a>. This talk stresses a very important aspect of modern JS performance: fastest application is the one that is essentially&nbsp;statically&nbsp;typed in it's nature.</p>
<p>Modern JavaScript VMs try to grasp "static" structure hidden inside dynamic JS code by utilizing <em>hidden classes</em> and <em>inline caches</em>. Take a look at <a href="http://s3.mrale.ph/nodecamp.eu/#41">my slide deck</a>&nbsp;to get a basic understanding of how those hidden classes are built and used.&nbsp;&nbsp;</p>
<p>For V8 it is also important to check how you store floating point numbers (and integers that exceed 31-bit range in case of ia32 version of v8) and use WebGL typed arrays if appropriate. These days V8 tries to adapt generic arrays' storage to the data you store in them, but understanding whether those optimizations kicked in or not might be difficult; thus I just recommend using typed arrays.</p>
<h3>GC is high on the profile</h3>
<p>Try to understand what your are allocating and (more important) what survives several GCs. The worst kind of object is the one that survives a couple of partial (aka scavenge) collections and then gets thrown away. This kind of workload is the most stressful for GC because it has to copy young objects around constantly. Objects that live long are less stressful (but you have to keep in mind that GC cost is proportional to the number of live objects). The best kind of object is the one that dies shortly after it's allocation. You can use <code>--trace-gc</code> to see GC pauses and you can use built in heap snapshots to figure out what takes space in your heap. [it might be hard or impossible to capture "middle-aged" garbage with heap snapshots because V8 does full garbage collection before taking snapshot thus effectively killing all such garbage].</p>
<h3>JS natives are high on the profile</h3>
<p>When I say _natives_ I mean built in methods of <code>String</code>/<code>Number</code>/<code>Boolean</code>/<code>RegExp</code>/<code>JSON</code> and global functions like <code>parseInt</code> etc. Here you can't optimize anything directly but you can try to figure out two things:</p>
<ul>
<li><strong>Try calling them less by changing your algorithms and/or fusing them into it.</strong> Some of those methods are very generic (e.g. forEach). Some can be fused with your functions (e.g. you have to parse integer contained in some stream: you can either build a temporary string character by character and pass it to parseInt or you can fuse parsing and reading from a stream; later is better)</li>
<li><strong>Is there some obvious performance problem with them?</strong> V8's implementation of the native method can be suboptimal. If you see a bug (or you suspect that it can be improved) please <a href="http://code.google.com/p/v8/issues/entry">file a bug</a> or write a question to <a href="https://groups.google.com/group/v8-users">v8-users</a> mailing list.</li>
</ul>
<h3>Some strange V8 internals are high on the profile</h3>
<p>In this case you can either read V8's source or send a question to&nbsp;<a href="https://groups.google.com/group/v8-users">v8-users</a> list.</p>
<h3>A lot of time is spent in your C++ code</h3>
<p>Sorry this is out of scope. Consult C++ optimization guides :-)</p>
<h2>Do you feel that V8's statistical profiler misses hotspot?</h2>
<p>Your best bet then is either hardware counters based tool like Linux <code>perf</code> for which V8 has support (see <code>v8/tools/ll_prof.py --help</code> for more details) or trying to spot&nbsp;anomalies&nbsp;by some sort of software counters based profiling. V8 has it's own simple software counters subsystem (try passing <code>--native-code-counters --dump-counters</code> to <code>d8</code> shell).</p>
<h2>Do you want to go deeper?</h2>
<p>If you feel that generated code is slow and you can improve it you should definitely check it out using flags <code>--print-code --code-comments</code>. You can also dump IR used by optimizing compiler with <code>--trace-hydrogen</code>. IR will be written into <code>hydrogen.cfg</code> file that can be viewed by <a href="http://java.net/projects/c1visualizer/">C1 Visualizer</a>.</p>
<h2>Are you still lost?</h2>
<p>Drop a line to <a href="mailto:me@mrale.ph">me</a> or better to <a href="https://groups.google.com/group/v8-users">v8-users</a> mailing list. Try your best to provide as much context as possible (a standalone JS benchmark is the best way). It's nearly impossible to diagnose performance problems based on vague descriptions of what you are trying to achieve and how slow it runs.</p>
<blockquote><em>There is something to be learned from a rainstorm. When meeting with a sudden shower, you try not to get wet and run quickly along the road. But doing such things as passing under the eaves of houses, you still get wet. When you are resolved from the beginning, you will not be perplexed, though you still get the same soaking</em><br />&mdash; <a href="http://en.wikipedia.org/wiki/Hagakure">Hagakure</a> by&nbsp;<a href="http://en.wikipedia.org/wiki/Yamamoto_Tsunetomo" title="Yamamoto Tsunetomo">Yamamoto Tsunetomo.</a></blockquote>
<p>Similarly you have to be resolved from the beginning when you want to optimize your app. Randomly tweaking things in panic here and there does not help.</p>
<p>Understand before you act.</p>